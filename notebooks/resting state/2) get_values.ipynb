{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2edd11f-f215-417d-84c7-856eefa7d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import antropy as ant\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6656a3-8a47-4b18-9d6e-ac859656e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e34483-1b1e-4031-a930-320c65f458fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/13 [00:58<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 111\u001b[0m\n\u001b[1;32m    107\u001b[0m hjorth_complexity\u001b[38;5;241m.\u001b[39mappend(complexity)\n\u001b[1;32m    110\u001b[0m fsi, info \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39mfishershannon_information(time_series)\n\u001b[0;32m--> 111\u001b[0m lle, info \u001b[38;5;241m=\u001b[39m \u001b[43mnk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplexity_lyapunov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_series\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m sampen, parameters \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39mentropy_sample(time_series)\n\u001b[1;32m    113\u001b[0m pen, info \u001b[38;5;241m=\u001b[39m nk\u001b[38;5;241m.\u001b[39mentropy_permutation(time_series)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/neurokit2/complexity/complexity_lyapunov.py:159\u001b[0m, in \u001b[0;36mcomplexity_lyapunov\u001b[0;34m(signal, delay, dimension, method, separation, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m method \u001b[38;5;241m=\u001b[39m method\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrosenstein\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrosenstein1993\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 159\u001b[0m     le, parameters \u001b[38;5;241m=\u001b[39m \u001b[43m_complexity_lyapunov_rosenstein\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmakowski\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    163\u001b[0m     le, parameters \u001b[38;5;241m=\u001b[39m _complexity_lyapunov_makowski(\n\u001b[1;32m    164\u001b[0m         signal, delay, dimension, separation, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    165\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/neurokit2/complexity/complexity_lyapunov.py:301\u001b[0m, in \u001b[0;36m_complexity_lyapunov_rosenstein\u001b[0;34m(signal, delay, dimension, separation, len_trajectory, show, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Find indices of nearest neighbours\u001b[39;00m\n\u001b[1;32m    300\u001b[0m ntraj \u001b[38;5;241m=\u001b[39m m \u001b[38;5;241m-\u001b[39m len_trajectory \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 301\u001b[0m min_dist_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdists\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mntraj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mntraj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# exclude last few indices\u001b[39;00m\n\u001b[1;32m    304\u001b[0m min_dist_indices \u001b[38;5;241m=\u001b[39m min_dist_indices\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Follow trajectories of neighbour pairs for len_trajectory data points\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1325\u001b[0m, in \u001b[0;36margmin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths1 = glob.glob('epochs_ar/*')\n",
    "paths2 = glob.glob('epochs_ar/con??-day0-control_epo.fif')\n",
    "paths3 = glob.glob('epochs_button_ar/*')\n",
    "\n",
    "paths1.sort()\n",
    "paths2.sort()\n",
    "paths3.sort()\n",
    "\n",
    "# Concatenate the sorted lists in the desired order\n",
    "paths = paths1 + paths2 + paths3\n",
    "paths = paths2\n",
    "\n",
    "\n",
    "first_run = True\n",
    "for path in tqdm(paths):\n",
    "    \n",
    "    components = re.split('[-_]', os.path.basename(path))\n",
    "    sub = components[0][3:]\n",
    "    day = components[1]\n",
    "    condition = components[2]\n",
    "    if components[3][:-1] == 'button#':\n",
    "        button = components[3]\n",
    "        jhana = components[4]\n",
    "    else: \n",
    "        button = 'all'\n",
    "        jhana = 'all'\n",
    "    if day == \"day0\":\n",
    "        sub = int(sub)+10\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #analysis\n",
    "    epochs = mne.read_epochs(path)\n",
    "    \n",
    "    if len(epochs) < 10: \n",
    "        lempel_ziv_norm = np.nan\n",
    "        permutation_entropy = np.nan\n",
    "        spectral_entropy = np.nan\n",
    "        sample_entropy = np.nan\n",
    "        hjorth_mobility = np.nan\n",
    "        hjorth_complexity = np.nan\n",
    "        average_corr_all = np.nan\n",
    "    \n",
    "    else:                   \n",
    "        picks = mne.pick_types(epochs.info, eeg=True, exclude='bads')\n",
    "        epochs_good_eeg = epochs.pick(picks)\n",
    "        ch_names = epochs_good_eeg.info['ch_names']\n",
    "        data = epochs_good_eeg.get_data(copy=False)\n",
    "        n_epochs, n_channels, _ = data.shape\n",
    "\n",
    "        ###################\n",
    "        ### Compute PSD ###\n",
    "        ###################\n",
    "        frequency_bands = {\n",
    "            'delta': (0.5, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 12),\n",
    "            'beta': (12, 30),\n",
    "            'gamma': (30, 45)\n",
    "        }\n",
    "\n",
    "        band_powers = {band: [] for band in frequency_bands}\n",
    "        psd = epochs.compute_psd(fmin=0.5, fmax=45, n_fft=256, method='welch')\n",
    "        psds, freqs = psd.get_data(return_freqs=True)\n",
    "        \n",
    "        band_powers = {band: np.zeros((psds.shape[1],)) for band in frequency_bands}\n",
    "        \n",
    "        for band, (fmin, fmax) in frequency_bands.items():\n",
    "            freq_mask = (freqs >= fmin) & (freqs < fmax)\n",
    "            band_power = np.mean(psds[:, :, freq_mask], axis=(0, 2))  # Mean across epochs and frequencies\n",
    "            band_powers[band] = band_power\n",
    "        \n",
    "            \n",
    "        ###################\n",
    "        ### Compute complexity measures ###\n",
    "        ###################\n",
    "\n",
    "    \n",
    "        for channel, ch_name in enumerate(ch_names):\n",
    "            lempel_ziv_norm = []\n",
    "            permutation_entropy = []\n",
    "            spectral_entropy = []\n",
    "            sample_entropy = []\n",
    "            hjorth_mobility = []\n",
    "            hjorth_complexity = []\n",
    "            average_corr_all = []\n",
    "            nk_fsi = []\n",
    "            nk_lle = []\n",
    "            nk_sampen = []\n",
    "            nk_pen = []\n",
    "            nk_lzc = []\n",
    "\n",
    "            for epoch in range(len(data)):\n",
    "            \n",
    "                time_series = data[epoch,channel,:]\n",
    "                threshold = np.median(time_series)\n",
    "                binary_sequence = (time_series > threshold).astype(int)\n",
    "                binary_string = ''.join(binary_sequence.astype(str))\n",
    "        \n",
    "                lempel_ziv_norm.append(ant.lziv_complexity(binary_string, normalize=True))\n",
    "                permutation_entropy.append(ant.perm_entropy(time_series, normalize=True))\n",
    "                spectral_entropy.append(ant.spectral_entropy(time_series, sf=100, method='welch', normalize=True))\n",
    "                sample_entropy.append(ant.sample_entropy(time_series))\n",
    "                mobility, complexity = ant.hjorth_params(time_series)\n",
    "                hjorth_mobility.append(mobility)\n",
    "                hjorth_complexity.append(complexity)\n",
    "\n",
    "\n",
    "                fsi, info = nk.fishershannon_information(time_series)\n",
    "                lle, info = nk.complexity_lyapunov(time_series)\n",
    "                sampen, parameters = nk.entropy_sample(time_series)\n",
    "                pen, info = nk.entropy_permutation(time_series)\n",
    "                lzc, info = nk.complexity_lempelziv(time_series)\n",
    "\n",
    "                nk_fsi.append(fsi*10**4)\n",
    "                nk_lle.append(lle*100)\n",
    "                nk_sampen.append(sampen)\n",
    "                nk_pen.append(pen)\n",
    "                nk_lzc.append(lzc)\n",
    "\n",
    "                \n",
    "            lempel_ziv_norm = np.round(np.mean(lempel_ziv_norm), 4)\n",
    "            permutation_entropy = np.round(np.mean(permutation_entropy), 4)\n",
    "            spectral_entropy = np.round(np.mean(spectral_entropy), 4)\n",
    "            sample_entropy = np.round(np.mean(sample_entropy), 4)\n",
    "            hjorth_mobility = np.round(np.mean(hjorth_mobility), 4)\n",
    "            hjorth_complexity = np.round(np.mean(hjorth_complexity), 4)\n",
    "            nk_fsi = np.round(np.mean(nk_fsi), 4)\n",
    "            nk_lle = np.round(np.mean(nk_lle), 4)\n",
    "            nk_sampen = np.round(np.mean(nk_sampen), 4)\n",
    "            nk_pen = np.round(np.mean(nk_pen), 4)\n",
    "            nk_lzc = np.round(np.mean(lzc),4)\n",
    "\n",
    "\n",
    "            #correlation_matrix = np.corrcoef(data[epoch,:,:])\n",
    "            #upper_triangle_indices = np.triu_indices(len(ch_names), k=1)\n",
    "            #average_corr = np.mean(correlation_matrix[upper_triangle_indices])\n",
    "            #average_corr_all.append(average_corr)\n",
    "\n",
    "            \n",
    "            df_data = {\n",
    "                'sub': sub, \n",
    "                'day': day, \n",
    "                'condition': condition,\n",
    "                'button': button,\n",
    "                'jhana': jhana,\n",
    "                'ch_name': ch_name,\n",
    "                'n_epochs': n_epochs,\n",
    "                'n_channels': n_channels,\n",
    "                \n",
    "                'lempel_ziv_norm': lempel_ziv_norm,\n",
    "                'permutation_entropy': permutation_entropy,\n",
    "                'spectral_entropy': spectral_entropy,\n",
    "                'sample_entropy': sample_entropy,\n",
    "                'hjorth_mobility': hjorth_mobility,\n",
    "                'hjorth_complexity': hjorth_complexity,\n",
    "                'nk_fsi': nk_fsi,\n",
    "                'nk_lle': nk_lle,\n",
    "                'nk_sampen': nk_sampen,\n",
    "                'nk_pen': nk_pen,\n",
    "                'nk_lzc': nk_lzc,\n",
    "                \n",
    "                'delta': np.round(band_powers['delta'][channel]*10**12,4),\n",
    "                'theta': np.round(band_powers['theta'][channel]*10**12,4),\n",
    "                'alpha': np.round(band_powers['alpha'][channel]*10**12,4),\n",
    "                'beta': np.round(band_powers['beta'][channel]*10**12,4),\n",
    "                'gamma': np.round(band_powers['gamma'][channel]*10**12,4),\n",
    "                    }\n",
    "\n",
    "        \n",
    "            df_row = pd.DataFrame([df_data])\n",
    "            \n",
    "            if first_run:\n",
    "                df_results = df_row\n",
    "                first_run = False\n",
    "            else:\n",
    "                df_results = pd.concat([df_results, df_row], ignore_index=True)\n",
    "            df_results.to_csv('eeg_metrics_TMP.csv', index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377e3e0-0ca5-499d-a95e-88ddf704e2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
